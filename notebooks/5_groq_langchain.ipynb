{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f1220d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a875a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"openai/gpt-oss-20b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dd6da12",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm.invoke(\"can you expalin me GEN-AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ced300d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### GEN‑AI = Generative AI  \n",
      "*(sometimes called “Generative Pre‑trained Transformers” or “Generative Models”)*  \n",
      "\n",
      "---\n",
      "\n",
      "## 1. What is Generative AI?\n",
      "\n",
      "Generative AI refers to a family of machine‑learning models that **create new data**—text, images, audio, video, code, even 3‑D shapes—rather than just classifying or regressing on existing data.  \n",
      "Think of it as a very advanced “copy‑and‑paste” system that learns the *style*, *structure*, and *content* of a dataset and then produces brand‑new items that look like they belong to that same distribution.\n",
      "\n",
      "| Traditional AI | Generative AI |\n",
      "|----------------|---------------|\n",
      "| Predicts labels (spam? no spam?) | Generates content (novel text, a photo of a cat that never existed) |\n",
      "| Works on *existing* data | Produces *new* data that never existed before |\n",
      "| Example models: Decision trees, SVMs, CNNs for classification | Example models: GPT‑4, DALL‑E, Stable Diffusion, AudioLDM |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Core Technologies\n",
      "\n",
      "| Technology | How it works (simplified) | Typical use |\n",
      "|------------|--------------------------|-------------|\n",
      "| **Transformer architecture** | Uses self‑attention to model relationships between tokens (words, pixels, audio samples). Trained on large corpora with a *next‑token* objective. | GPT‑4, BERT, T5 |\n",
      "| **Diffusion models** | Start with random noise and iteratively denoise to produce an image (or audio). Trained by learning to reverse a diffusion process. | DALL‑E 2, Stable Diffusion |\n",
      "| **Variational Autoencoders (VAEs)** | Encode data into a latent space, then decode to reconstruct. Latent vectors can be sampled to generate new data. | StyleGAN, VQ‑VAE |\n",
      "| **Generative Adversarial Networks (GANs)** | Two networks (generator vs. discriminator) play a game; generator learns to produce realistic samples. | DeepFake, StyleGAN |\n",
      "| **Reinforcement Learning from Human Feedback (RLHF)** | Fine‑tunes a model using human ratings to align outputs with user intent. | ChatGPT, Claude |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. How do they “learn”?\n",
      "\n",
      "1. **Pre‑training**  \n",
      "   *Collect a huge dataset* (e.g., billions of web pages, millions of images).  \n",
      "   *Train the model* to predict the next token (text) or pixel (image) given the previous context.  \n",
      "   This stage teaches the model grammar, facts, visual patterns, etc.\n",
      "\n",
      "2. **Fine‑tuning / Prompting**  \n",
      "   *Adapt* the pre‑trained weights to a specific task or style.  \n",
      "   *Prompt engineering* (providing a starting text or image prompt) can steer the generation without changing weights.\n",
      "\n",
      "3. **Alignment**  \n",
      "   Use RLHF or other techniques to ensure the model’s outputs are safe, useful, and aligned with human values.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. What can it do?\n",
      "\n",
      "| Domain | Examples |\n",
      "|--------|----------|\n",
      "| **Text** | Summaries, essays, code generation, chatbots, translation. |\n",
      "| **Images** | Photo‑realistic images from captions, style transfer, inpainting, upscaling. |\n",
      "| **Audio** | Speech synthesis, music composition, voice cloning. |\n",
      "| **Video** | Frame interpolation, text‑to‑video, deep‑fake generation. |\n",
      "| **3‑D** | Generating meshes or point clouds for AR/VR. |\n",
      "| **Multimodal** | Captioning images, generating images from text, or vice versa. |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Why is it exciting?\n",
      "\n",
      "1. **Creativity & Productivity** – Artists, writers, designers can prototype ideas instantly.  \n",
      "2. **Automation** – Repetitive content creation (product descriptions, news briefs) can be scaled.  \n",
      "3. **Personalization** – Tailor content to user preferences in real time.  \n",
      "4. **Accessibility** – Generate captions, translations, or assistive content for people with disabilities.  \n",
      "\n",
      "---\n",
      "\n",
      "## 6. Challenges & Ethical Concerns\n",
      "\n",
      "| Issue | What it means | Mitigation |\n",
      "|-------|---------------|------------|\n",
      "| **Hallucinations** | Model may produce plausible but false facts. | Fact‑checking layers, user prompts for citations. |\n",
      "| **Bias & Fairness** | Trained on biased data → biased outputs. | Diverse datasets, bias‑detection metrics, post‑hoc filtering. |\n",
      "| **Copyright** | Generated content may infringe on existing works. | Copyright‑aware training, watermarking, licensing checks. |\n",
      "| **Deepfakes** | Realistic fake media can spread misinformation. | Detection tools, digital signatures, policy enforcement. |\n",
      "| **Misuse** | Generating disallowed content (hate speech, instructions for wrongdoing). | Moderation policies, content filters, usage agreements. |\n",
      "\n",
      "---\n",
      "\n",
      "## 7. Quick Glossary\n",
      "\n",
      "| Term | What it means |\n",
      "|------|---------------|\n",
      "| **Token** | A unit of text (word, sub‑word, punctuation). |\n",
      "| **Prompt** | The input that tells the model what to generate. |\n",
      "| **Latent space** | A compressed representation of data inside a model. |\n",
      "| **Inference** | Using a trained model to generate new data. |\n",
      "| **Fine‑tuning** | Adjusting a pre‑trained model on a smaller, task‑specific dataset. |\n",
      "| **Zero‑shot / Few‑shot** | Generating outputs with little or no task‑specific training. |\n",
      "| **Chain of thought** | Prompting the model to “think out loud” to improve reasoning. |\n",
      "\n",
      "---\n",
      "\n",
      "## 8. A Very Simple Example\n",
      "\n",
      "**Prompt**: “Write a short poem about a moonlit beach.”  \n",
      "**GPT‑4** might output:\n",
      "\n",
      "```\n",
      "In silver waves that kiss the shore,\n",
      "The moonlight drifts across the floor.\n",
      "Soft whispers of the tide’s embrace,\n",
      "A hush that fills the night’s warm space.\n",
      "```\n",
      "\n",
      "Here, the model has *learned* the structure of a poem, the imagery of a beach, and the poetic language—then produced something brand‑new.\n",
      "\n",
      "---\n",
      "\n",
      "## 9. Getting Started\n",
      "\n",
      "1. **Choose a Platform**  \n",
      "   - OpenAI (ChatGPT, DALL‑E)  \n",
      "   - Google Gemini  \n",
      "   - Anthropic Claude  \n",
      "   - Stable Diffusion (open‑source)  \n",
      "\n",
      "2. **Learn Prompting**  \n",
      "   - Start with clear, concise prompts.  \n",
      "   - Use examples or “role‑play” prompts to guide style.  \n",
      "\n",
      "3. **Experiment**  \n",
      "   - Try generating text, images, or code.  \n",
      "   - Iterate on prompts to refine outputs.  \n",
      "\n",
      "4. **Build an Application**  \n",
      "   - Use APIs to integrate generation into a chatbot, content‑creation tool, or creative assistant.  \n",
      "\n",
      "---\n",
      "\n",
      "## 10. Bottom Line\n",
      "\n",
      "**Generative AI (GEN‑AI)** is the technology that lets computers *create*—to write, draw, compose, or design—by learning patterns from massive amounts of data. It’s a powerful tool that can augment human creativity, automate routine tasks, and open up new possibilities, but it also demands careful handling to address safety, ethics, and fairness.  \n",
      "\n",
      "Feel free to ask if you want deeper dives into any specific model, use‑case, or ethical aspect!\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
